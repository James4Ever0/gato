{
    "summary": "The code presents PatchPositionEncoding models, Residual Embedding layers with convolutional projection and group normalization, LocalPositionEncoding for tokenizing input using convolutions, and a \"DiscreteEmbedding\" class used in Gato model for natural language processing tasks.",
    "details": [
        {
            "comment": "This code defines a PatchPositionEncoding class which is a Layer that applies position encodings to image patches. It takes a GatoConfig or config dictionary as input, and initializes the layer with its width, discretize depth, and patch size. The _randomized_positions and _rounded_mean_positions functions are used internally for generating position encodings.",
            "location": "\"/media/root/Prima/works/gato/docs/src/gato/models/embedding.py\":0-34",
            "content": "import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom gato import GatoConfig\nfrom typing import Dict, Any, Union\ndef _randomized_positions(from_v, to_v):\n    pos = tf.random.uniform(from_v.shape, minval=0, maxval=1, dtype=tf.float32)\n    pos = pos * (to_v - from_v).cast(tf.float32)\n    return pos.cast(tf.int32)\ndef _rounded_mean_positions(from_v, to_v):\n    pos = (from_v + to_v).cast(tf.float32) / 2.\n    return pos.round()\nclass PatchPositionEncoding(layers.Layer):\n    def __init__(self,\n                 config: Union[GatoConfig, Dict[str, Any]],\n                 trainable=True, name=None, *args, **kwargs):\n        \"\"\"\n        Appendix C.3. Position Encodings\n        \"\"\"\n        super(PatchPositionEncoding, self).__init__(trainable=trainable, name=name, *args, **kwargs)\n        if isinstance(config, dict):\n            config = GatoConfig(**config)\n        self.config = config\n        self.embedding_dim = self.config.layer_width\n        self.discretize_depth = self.config.discretize_depth\n        self.patch_size = self.config.img_patch_size"
        },
        {
            "comment": "This code defines an embedding model for 2D positions. It initializes two embedding layers (row and col) based on the discretize_depth and embedding_dim parameters. The _discretize function is used to normalize pos values, and _discretize_interval returns the discretized versions of a given interval. Finally, the call method takes input_ids, row_pos, and col_pos as inputs and embeds them using the defined embedding layers.",
            "location": "\"/media/root/Prima/works/gato/docs/src/gato/models/embedding.py\":36-54",
            "content": "        self.row_embedding = layers.Embedding(self.discretize_depth, self.embedding_dim, name='row_embedding')\n        self.col_embedding = layers.Embedding(self.discretize_depth, self.embedding_dim, name='col_embedding')\n    def _discretize(self, pos):\n        return (pos * self.discretize_depth).round()\n    def _discretize_interval(self, interval):\n        pos_from, pos_to = interval\n        return self._discretize(pos_from), self._discretize(pos_to)\n    def call(self, inputs, *args, **kwargs):\n        # Appendix C.3. Position Encodings; Figure 15 | Patch position encodings.\n        training = kwargs['training'] if 'training' in kwargs else False\n        # input_ids must already be embedded by the resnet embedding function.\n        # row_pos and col_pos must be intervals which is tuple of (pos_from, pos_to)\n        # row_pos and col_pos must be normalized between [0, 1] to show their relativity.\n        input_ids, (row_pos, col_pos) = inputs\n        row_pos_from, row_pos_to = self._discretize_interval(row_pos)"
        },
        {
            "comment": "The code retrieves row and column position encodings from the embedding table, applies them to token embeddings produced by resnet, and either randomly samples a position within the quantized interval during training or takes the rounded mean of the interval during evaluation.",
            "location": "\"/media/root/Prima/works/gato/docs/src/gato/models/embedding.py\":55-72",
            "content": "        col_pos_from, col_pos_to = self._discretize_interval(col_pos)\n        if training:\n            # > During training a random index is uniformly sampled from the quantized interval.\n            row_pos = row_pos_from + _randomized_positions(row_pos_from, row_pos_to)\n            col_pos = col_pos_from + _randomized_positions(col_pos_from, col_pos_to)\n        else:\n            # > During evaluation we deterministically take the (rounded) mean of the interval.\n            row_pos = _rounded_mean_positions(row_pos_from, row_pos_to)\n            col_pos = _rounded_mean_positions(col_pos_from, col_pos_to)\n        # > Once row and column position encoding are retrieved from the embedding table,\n        # > they are added onto the token embedding produced by the resnet embedding function.\n        return input_ids + self.row_embedding(row_pos.cast(tf.int32)) + self.col_embedding(col_pos.cast(tf.int32))\n    def get_config(self):\n        config = super(PatchPositionEncoding, self).get_config()\n        config.update({"
        },
        {
            "comment": "The code defines a ResidualUnit class with GroupNormalization and Conv2D layers. It builds the layers in the build() method, initializing them with specified parameters such as filter count and kernel size. The class is part of the gato/gato/models/embedding.py file, indicating it might be used for model embedding operations.",
            "location": "\"/media/root/Prima/works/gato/docs/src/gato/models/embedding.py\":73-94",
            "content": "            'config': self.config.to_dict(),\n        })\n        return config\nclass ResidualUnit(layers.Layer):\n    def __init__(self, num_groups: int, filters: int, trainable=True, name=None, *args, **kwargs):\n        super(ResidualUnit, self).__init__(trainable=trainable, name=name, *args, **kwargs)\n        self.num_groups = num_groups\n        self.filters = filters\n        self.gn1 = self.gn2 = None\n        self.conv1 = self.conv2 = None\n        self.conv_proj = self.gn_proj = None\n    def build(self, input_shape):\n        self.gn1 = layers.GroupNormalization(groups=self.num_groups, name='gn1')\n        self.gn2 = layers.GroupNormalization(groups=self.num_groups, name='gn2')\n        self.conv1 = layers.Conv2D(filters=self.filters // 2, kernel_size=(3, 3), strides=(1, 1),\n                                   use_bias=False, padding='same', name='conv1')\n        self.conv2 = layers.Conv2D(filters=self.filters, kernel_size=(3, 3), strides=(2, 2),\n                                   use_bias=False, padding='same', name='conv2')"
        },
        {
            "comment": "The code defines a Residual Embedding layer with convolutional projection and group normalization. It uses the v2 ResNet architecture, GroupNorm instead of LayerNorm, and GELU instead of RELU activation functions. The class also includes an initializer method and a call function for processing inputs.",
            "location": "\"/media/root/Prima/works/gato/docs/src/gato/models/embedding.py\":95-122",
            "content": "        self.conv_proj = layers.Conv2D(filters=self.filters, kernel_size=(1, 1), strides=(2, 2),\n                                       use_bias=False, padding='same', name='conv_proj')\n        self.gn_proj = layers.GroupNormalization(groups=self.num_groups, name='gn_proj')\n    def call(self, inputs, *args, **kwargs):\n        # Supplementary Material B. Agent Data Tokenization Details; Figure 16\n        # > This block uses the v2 ResNet architecture, GroupNorm (instead of LayerNorm) normalization,\n        # > and GELU (instead RELU) activation functions.\n        x = inputs\n        residual = self.conv_proj(self.gn_proj(x))\n        x = self.gn1(x).gelu()\n        x = self.conv1(x)\n        x = self.gn2(x).gelu()\n        x = self.conv2(x)\n        return x + residual\nclass ResidualEmbedding(layers.Layer):\n    def __init__(self, config: Union[GatoConfig, Dict[str, Any]], trainable=True, name=None, *args, **kwargs):\n        \"\"\"\n        Appendix C.2. Embedding Function\n        \"\"\"\n        super(ResidualEmbedding, self).__init__(trainable=trainable, name=name, *args, **kwargs)"
        },
        {
            "comment": "This code initializes instance variables and defines the `build` method in a model. It checks if the input is a dictionary and creates an instance of `GatoConfig`. Then, it sets various attributes for the model's layers and builds the root convolution layer using a series of Conv2D, GroupNormalization, and Activation layers.",
            "location": "\"/media/root/Prima/works/gato/docs/src/gato/models/embedding.py\":124-143",
            "content": "        if isinstance(config, dict):\n            config = GatoConfig(**config)\n        self.config = config\n        self.root_conv = self.conv_proj = None\n        self.residual_units = None\n        self.num_patches = None\n    def build(self, input_shape):\n        if self.config.input_dim != self.config.layer_width:\n            self.conv_proj = layers.Conv2D(filters=self.config.layer_width,\n                                           kernel_size=(1, 1),\n                                           strides=(1, 1),\n                                           padding='same',\n                                           use_bias=False,\n                                           name='conv_proj')\n        self.root_conv = models.Sequential([\n            layers.Conv2D(filters=96, kernel_size=(7, 7), strides=(2, 2),\n                          use_bias=False, padding='same', name='conv_root'),\n            layers.GroupNormalization(groups=self.config.num_group_norm_groups, name='gn_root'),\n            layers.Activation('gelu', name='act_root')"
        },
        {
            "comment": "The code defines a model with residual units and applies convolutions to tokenize the input. It uses a ResNet block to embed tokens from image patches into feature maps, which is currently under discussion in issue #2. The model then reshapes the output based on the config parameters.",
            "location": "\"/media/root/Prima/works/gato/docs/src/gato/models/embedding.py\":144-165",
            "content": "        ])\n        self.residual_units = [ResidualUnit(num_groups=self.config.num_group_norm_groups,\n                                            filters=96 * 2 ** (i + 1),\n                                            name='residual_unit_{}'.format(i + 1))\n                               for i in range(3)]\n    def call(self, inputs, *args, **kwargs):\n        # Section 2.1 Tokenization.\n        x = self.root_conv(inputs)\n        # NOTE: Page 3-4, Section 2.2 Embedding input tokens and setting output targets\n        # > Tokens belonging to image patches for any time-step are embedded\n        # > using a single ResNet block to obtain a vector per patch.\n        # I don't think that transforming single 16x16 patch into feature map\n        # with depth 768 at once does not give advantages coming from inductive bias.\n        # This is currently discussing in issue #2\n        for block in self.residual_units:\n            x = block(x)\n        if self.conv_proj is not None:\n            x = self.conv_proj(x)\n        x = x.reshape((-1, inputs.shape[1], self.config.layer_width))"
        },
        {
            "comment": "This code defines a LocalPositionEncoding class that inherits from the layers.Layer base class. It initializes an embedding layer using ResidualEmbedding and builds the embedding layer based on the input shape. The call method applies local position encodings to inputs, following the specifications in Appendix C.3 of the associated paper.",
            "location": "\"/media/root/Prima/works/gato/docs/src/gato/models/embedding.py\":166-194",
            "content": "        return x\n    def get_config(self):\n        config = super(ResidualEmbedding, self).get_config()\n        config.update({\n            'config': self.config.to_dict()\n        })\n        return config\nclass LocalPositionEncoding(layers.Layer):\n    def __init__(self, config: Union[GatoConfig, Dict[str, Any]], trainable=True, name=None, *args, **kwargs):\n        \"\"\"\n        Appendix C.3. Position Encodings > Local Observation Position Encodings\n        \"\"\"\n        super(LocalPositionEncoding, self).__init__(trainable=trainable, name=name, *args, **kwargs)\n        if isinstance(config, dict):\n            config = GatoConfig(**config)\n        self.config = config\n        self.embedding = None\n    def build(self, input_shape):\n        self.embedding = layers.Embedding(self.config.token_sequence_length, self.config.layer_width)\n        self.built = True\n    def call(self, inputs, *args, **kwargs):\n        # Appendix C.3. Position Encodings > Local Observation Position Encodings; Figure 18 | Local position encodings."
        },
        {
            "comment": "The code defines a class called \"DiscreteEmbedding\" which is a type of layer in the Gato model. This layer builds an embedding matrix for discrete input tokens based on a given configuration. It also includes a function called \"get_config\" to retrieve the current configuration of the layer, and another function called \"build\" to initialize the embedding matrix based on the input shape provided. The code snippet also mentions the concept of position encoding and masking of action tokens in the model's processing.",
            "location": "\"/media/root/Prima/works/gato/docs/src/gato/models/embedding.py\":195-225",
            "content": "        # > Note that no position encodings are added to action tokens.\n        # So I added `obs_mask` to mask the action token into zeros.\n        obs_pos, obs_mask = inputs\n        embed = self.embedding(obs_pos)\n        ones = tf.ones((embed.shape[0], 1, self.config.layer_width), dtype=tf.float32)\n        obs_mask = obs_mask.cast(tf.float32).transpose().matmul(ones)\n        return embed * obs_mask\n    def get_config(self):\n        config = super(LocalPositionEncoding, self).get_config()\n        config.update({\n            'config': self.config.to_dict()\n        })\n        return config\nclass DiscreteEmbedding(layers.Layer):\n    def __init__(self, config: Union[GatoConfig, Dict[str, Any]], trainable=True, name=None, *args, **kwargs):\n        super(DiscreteEmbedding, self).__init__(trainable=trainable, name=name, *args, **kwargs)\n        if isinstance(config, dict):\n            config = GatoConfig(**config)\n        self.config = config\n        self.embedding = None\n    def build(self, input_shape):\n        # Appendix C.1. Transformer Hyperparameters"
        },
        {
            "comment": "This code defines a class for a shared embedding layer, which is used in natural language processing tasks. It uses TensorFlow's Embedding layer with configurable input size and layer width, and returns the embedding of inputs passed to the call method. The get_config method returns the configuration details of the layer.",
            "location": "\"/media/root/Prima/works/gato/docs/src/gato/models/embedding.py\":226-241",
            "content": "        # Shared Embedding\n        with tf.name_scope('discrete_shared_embedding'):\n            self.embedding = layers.Embedding(self.config.embedding_input_size,\n                                              self.config.layer_width,\n                                              name='discrete_embedding')\n        self.built = True\n    def call(self, inputs, *args, **kwargs):\n        return self.embedding(inputs)\n    def get_config(self):\n        config = super(DiscreteEmbedding, self).get_config()\n        config.update({\n            'config': self.config.to_dict()\n        })\n        return config"
        }
    ]
}