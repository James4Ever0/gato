{"_default": {"1": {"path": "/README.md", "hash": "26eddd9ad9fbc30ef6540cbbf8950e7b", "title": "Gato: Unofficial Transformer Implementation"}, "2": {"path": "/README.md:1-15", "hash": "6322bd6b7ceafb2d8692f51bc28e96f2", "title": "Unofficial Gato Agent Implementation"}, "3": {"path": "/README.md:16-35", "hash": "cb2d3f131ed95d860901aa2cc86b3444", "title": "Understanding Gato Architecture and Tokenizing"}, "4": {"path": "/README.md:37-66", "hash": "3c52596f73d14e5749fd15043ddd1b14", "title": "Gato Model Instance Creation and Fake Input Generation"}, "5": {"path": "/README.md:67-87", "hash": "82a3478339b28b58a4276e7436a1c066", "title": "GATO: Vision-Language Task Model Initialization"}, "6": {"path": "/README.md:88-111", "hash": "3cd160347d08ecbd64890d54f31fa10c", "title": "Architecture Variants of Gato"}, "7": {"path": "/README.md:112-140", "hash": "50420a3b06a13182c357ee0588acb564", "title": "Residual Embedding Layer in Gato"}, "8": {"path": "/README.md:142-176", "hash": "b1868da25fccd67ad13eb1470c54e429", "title": "Position Encodings and Embeddings for Observation Tokens"}, "9": {"path": "/README.md:178-192", "hash": "eaeafa20be24447f9c7cec3f640d1d6e", "title": "Title: \"TensorFlow 2.11.0+ Requirements\""}, "10": {"path": "/gato/__init__.py", "hash": "85bf8dfdff0f672dc30da10d0570bcd5", "title": "Gato: Efficient Tensor Chaining"}, "11": {"path": "/gato/config.py", "hash": "d007f713b8fd9da58a73c9c056c4b8eb", "title": "ML Model Initialization and Configuration"}, "12": {"path": "/gato/config.py:1-34", "hash": "b35381c17f53961a22df04b802fd3a8b", "title": "Gato Config: Versatile Model Parameters"}, "13": {"path": "/gato/config.py:36-58", "hash": "8d40d671663f2d4bba2e6a2b126b8366", "title": "Hyperparameters Setup for ML Model"}, "14": {"path": "/gato/config.py:60-80", "hash": "9d9f5cb8a40eb17ad3bd1c5658492c7b", "title": "Config Class for Gato Model"}, "15": {"path": "/gato/models/__init__.py", "hash": "5857672526260593026daf3083848788", "title": "Gato Model Architecture"}, "16": {"path": "/gato/models/__init__.py:1-22", "hash": "f9d5ddf6e4e58b58f3b89c6227945c2b", "title": "Gato Class Definition"}, "17": {"path": "/gato/models/__init__.py:23-42", "hash": "95a70246b2a0c0d7bf9c146ebab74937", "title": "Multi-Encoding Model Class"}, "18": {"path": "/gato/models/__init__.py:43-68", "hash": "fa3cee62ddd3b786a0a79491039f6309", "title": "Gato Transformer Initialization"}, "19": {"path": "/gato/models/__init__.py:69-96", "hash": "43b062a890bf866667ea7cbf857407f2", "title": "Transformer Class Initialization"}, "20": {"path": "/gato/models/__init__.py:97-110", "hash": "c4b2adee67d10ce097d92f2d1bf6829f", "title": "Patch Embedding Class"}, "21": {"path": "/gato/models/embedding.py", "hash": "e7a8506d45416dddd5aafb38ac58ef9e", "title": "Gato Embedding Models: Conv & Group Norm"}, "22": {"path": "/gato/models/embedding.py:1-35", "hash": "0624982f6d30b9a20fa2b2cad726faa4", "title": "PatchPositionEncoding Layer: Image Patch Encoding with Position Encodings"}, "23": {"path": "/gato/models/embedding.py:37-55", "hash": "e76ecadaec06e432203071b804b6c359", "title": "2D Position Embedding Model"}, "24": {"path": "/gato/models/embedding.py:56-73", "hash": "c29d20a7fb7fb85b3eb26658e25ce7ce", "title": "Embedding Position Sampling"}, "25": {"path": "/gato/models/embedding.py:74-95", "hash": "aeb88d8cc79937eb079fc3d430e1a758", "title": "Residual Unit with Normalization"}, "26": {"path": "/gato/models/embedding.py:96-123", "hash": "ba33378eb39fdbb99b66438ced265753", "title": "Residual Embedding Layer: GroupNorm and GELU"}, "27": {"path": "/gato/models/embedding.py:125-144", "hash": "d685005ecbef64e42e9fede303f9454a", "title": "Building Gato Model Layers"}, "28": {"path": "/gato/models/embedding.py:145-166", "hash": "d12946951326266c9a6846dd8a0dd9b5", "title": "ResNet Block for Token Embedding"}, "29": {"path": "/gato/models/embedding.py:167-195", "hash": "c82c2073a0abc70581947441b3a397c4", "title": "LocalPositionEncoding Layer"}, "30": {"path": "/gato/models/embedding.py:196-226", "hash": "834e85071f58000b21988e9586cc0ed8", "title": "Discrete Embedding Layer in Gato"}, "31": {"path": "/gato/models/embedding.py:227-242", "hash": "bc3f3174faf6611d8c6e3f12dd11f4f9", "title": "Shared Embedding Layer for NLP"}, "32": {"path": "/gato/models/tokenizers.py", "hash": "bb08094cfd735bd2c0adb9a93774f680", "title": "Mu-Law Continuous Value Tokenizer"}, "33": {"path": "/gato/models/tokenizers.py:1-34", "hash": "2960e2552e3e664e90b4d4e67e54d876", "title": "Mu-Law Encoding Continuous Values Tokenizer"}, "34": {"path": "/gato/models/tokenizers.py:35-47", "hash": "c8a60dab0849ab83419b8e5f098f83d6", "title": "Continuous Value Tokenizer"}, "35": {"path": "/gato/models/transformer.py", "hash": "612f03dcada4f994083e47681073fffb", "title": "Attention-Based Transformer Model for Text Analysis"}, "36": {"path": "/gato/models/transformer.py:1-30", "hash": "f03d00dd78a2f56574eb9a8c61bee8ba", "title": "Transformer Block Implementation"}, "37": {"path": "/gato/models/transformer.py:31-47", "hash": "11c529ce83b2958358d3c161ce8186bb", "title": "Attention-based Transformer Model with Layer Normalization"}, "38": {"path": "/gato/models/transformer.py:48-70", "hash": "481c799aa094188649842b7219325a29", "title": "Pre-Normalized Transformer Block with Double Layer Normalization"}, "39": {"path": "/setup.py", "hash": "4184862ab6366f6361f997f87dc5d424", "title": "Setup Script for Gato-TF Package"}}}